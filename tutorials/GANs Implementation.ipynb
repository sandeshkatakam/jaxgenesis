{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "641d3830",
   "metadata": {},
   "source": [
    "# Generative Models in JAX Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a4bc0",
   "metadata": {},
   "source": [
    "## Table of contents:\n",
    "\n",
    "* GANs\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c1842b",
   "metadata": {},
   "source": [
    "## Generative Adversarial Networks:\n",
    "\n",
    "Model architectures Implemented:\n",
    "* Vanilla GAN\n",
    "* DC GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5aa79",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56407d1",
   "metadata": {},
   "source": [
    "## Dataset Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f7e920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f8a6aed08c4031b81c49764fc65717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c8a89d27804dc6b0ad4fbf9b74d93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05016584ec224e1c932cc5be106cfa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951a3d2c475544d193689d4c162e9c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../dataset/data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../dataset/data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "with open(\"../config-gans.json\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "if params[\"dataset\"] == \"MNIST\":\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"../dataset/data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"../dataset/data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor()\n",
    "    )\n",
    "elif params[\"dataset\"] == \"CIFAR10\":\n",
    "    training_data = datasets.CIFAR10(\n",
    "        root = \"data\",\n",
    "        train = True,\n",
    "        download = True,\n",
    "        transform = ToTensor()\n",
    "    )\n",
    "    test_data = datasets.CIFAR10(\n",
    "        root = \"data\",\n",
    "        train   = False,\n",
    "        download = True,\n",
    "        tranform = ToTensor()\n",
    "    )\n",
    "elif params[\"dataset\"] == \"CelebA\":\n",
    "    training_data = datasets.CelebA(\n",
    "        root = \"data\",\n",
    "        train = True,\n",
    "        download = True,\n",
    "        tranform = ToTensor()\n",
    "    )\n",
    "    test_data = datasets.CelebA(\n",
    "        root = \"data\",\n",
    "        train = True,\n",
    "        download = True,\n",
    "        tranform = ToTensor()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d5f5a",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d194a9d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jax\u001b[38;5;241m.\u001b[39mpmap, static_broadcasted_argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_state\u001b[39m(rng, model_cls, input_shape): \n\u001b[0;32m      3\u001b[0m   \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Create the training state given a model class. \"\"\"\u001b[39;00m \n\u001b[0;32m      4\u001b[0m   model \u001b[38;5;241m=\u001b[39m model_cls()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'partial' is not defined"
     ]
    }
   ],
   "source": [
    "@partial(jax.pmap, static_broadcasted_argnums=(1, 2))\n",
    "def create_state(rng, model_cls, input_shape): \n",
    "  r\"\"\"Create the training state given a model class. \"\"\" \n",
    "  model = model_cls()\n",
    "\n",
    "  tx = optax.adam(0.0002, b1=0.5, b2=0.999)\n",
    "  variables = model.init(rng, jnp.ones(input_shape))\n",
    "\n",
    "  state = TrainState.create(apply_fn=model.apply, tx=tx, \n",
    "      params=variables['params'], batch_stats=variables['batch_stats'])\n",
    "  \n",
    "  return state\n",
    "\n",
    "\n",
    "@jax.pmap\n",
    "def sample_from_generator(generator_state, input_noise):\n",
    "  \"\"\"Sample from the generator in evaluation mode.\"\"\"\n",
    "  generated_data = generator_state.apply_fn(\n",
    "      {'params': generator_state.params,\n",
    "       'batch_stats': generator_state.batch_stats},\n",
    "      input_noise, train=False, mutable=False)\n",
    "  return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289dc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "983d2ad1",
   "metadata": {},
   "source": [
    "# Vanilla GAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanilla_gan(nn.module):\n",
    "    super().__init__()\n",
    "    def __init__(self):\n",
    "        \n",
    "    def __call__():\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "class Generator(nn.module):\n",
    "    features: int = 64\n",
    "    dtype: type = jnp.float32\n",
    "        \n",
    "    @nncompact\n",
    "    def __call__():\n",
    "        conv_transpose = partial(nn.ConvTranspose, padding='VALID',\n",
    "                             kernel_init=normal_init(0.02), dtype=self.dtype)\n",
    "        batch_norm = partial(nn.BatchNorm, use_running_average=not train, axis=-1, \n",
    "                             scale_init=normal_init(0.02), dtype=self.dtype)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    class Generator(nn.Module):\n",
    "  features: int = 64\n",
    "  dtype: type = jnp.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e464b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100dc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(hk.Module):\n",
    "    \"\"\" Generator Network \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3594d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(hk.Module):\n",
    "  \"\"\"Generator network.\"\"\"\n",
    "\n",
    "  def __init__(self, output_channels=(32, 1), name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.output_channels = output_channels\n",
    "\n",
    "\n",
    "  def __call__(self, x):\n",
    "    \"\"\"Maps noise latents to images.\"\"\"\n",
    "    x = hk.Linear(7 * 7 * 64)(x)\n",
    "    x = jnp.reshape(x, x.shape[:1] + (7, 7, 64))\n",
    "    for output_channels in self.output_channels:\n",
    "      x = jax.nn.relu(x)\n",
    "    \n",
    "      x = hk.Conv2DTranspose(output_channels=output_channels,\n",
    "                             kernel_shape=[5, 5],\n",
    "                             stride=2,\n",
    "                             padding=\"SAME\")(x)\n",
    "    \n",
    "     \n",
    "    # We use a tanh to ensure that the generated samples are in the same\n",
    "    # range as the data.\n",
    "    return jnp.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774da207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(hk.Module):\n",
    "  \"\"\"Discriminator network.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               output_channels=(8, 16, 32, 64, 128),\n",
    "               strides=(2, 1, 2, 1, 2),\n",
    "               name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.output_channels = output_channels\n",
    "    self.strides = strides\n",
    "\n",
    "  def __call__(self, x):\n",
    "    \"\"\"Classifies images as real or fake.\"\"\"\n",
    "    for output_channels, stride in zip(self.output_channels, self.strides):\n",
    "      x = hk.Conv2D(output_channels=output_channels,\n",
    "                    kernel_shape=[5, 5],\n",
    "                    stride=stride,\n",
    "                    padding=\"SAME\")(x)\n",
    "      x = jax.nn.leaky_relu(x, negative_slope=0.2)\n",
    "    x = hk.Flatten()(x)\n",
    "    # We have two classes: 0 = input is fake, 1 = input is real.\n",
    "    logits = hk.Linear(2)(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe760f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "  \"\"\"A basic GAN.\"\"\"\n",
    "\n",
    "  def __init__(self, num_latents):\n",
    "    self.num_latents = num_latents\n",
    "\n",
    "    # Define the Haiku network transforms.\n",
    "    # We don't use BatchNorm so we don't use `with_state`.\n",
    "    self.gen_transform = hk.without_apply_rng(\n",
    "        hk.transform(lambda *args: Generator()(*args)))\n",
    "    self.disc_transform = hk.without_apply_rng(\n",
    "        hk.transform(lambda *args: Discriminator()(*args)))\n",
    "\n",
    "    # Build the optimizers.\n",
    "    self.optimizers = GANTuple(gen=optax.adam(1e-4, b1=0.5, b2=0.9),\n",
    "                               disc=optax.adam(1e-4, b1=0.5, b2=0.9))\n",
    "\n",
    "  @functools.partial(jax.jit, static_argnums=0)\n",
    "  def initial_state(self, rng, batch):\n",
    "    \"\"\"Returns the initial parameters and optimize states.\"\"\"\n",
    "    # Generate dummy latents for the generator.\n",
    "    dummy_latents = jnp.zeros((batch.shape[0], self.num_latents))\n",
    "\n",
    "    # Get initial network parameters.\n",
    "    rng_gen, rng_disc = jax.random.split(rng)\n",
    "    params = GANTuple(gen=self.gen_transform.init(rng_gen, dummy_latents),\n",
    "                      disc=self.disc_transform.init(rng_disc, batch))\n",
    "    print(\"Generator: \\n\\n{}\\n\".format(tree_shape(params.gen)))\n",
    "    print(\"Discriminator: \\n\\n{}\\n\".format(tree_shape(params.disc)))\n",
    "\n",
    "    # Initialize the optimizers.\n",
    "    opt_state = GANTuple(gen=self.optimizers.gen.init(params.gen),\n",
    "                         disc=self.optimizers.disc.init(params.disc))\n",
    "    return GANState(params=params, opt_state=opt_state)\n",
    "\n",
    "\n",
    "    def sample(self, rng, gen_params, num_samples):\n",
    "    \"\"\"Generates images from noise latents.\"\"\"\n",
    "    latents = jax.random.normal(rng, shape=(num_samples, self.num_latents))\n",
    "    return self.gen_transform.apply(gen_params, latents)\n",
    "\n",
    "  def gen_loss(self, gen_params, rng, disc_params, batch):\n",
    "    \"\"\"Generator loss.\"\"\"\n",
    "    # Sample from the generator.\n",
    "    fake_batch = self.sample(rng, gen_params, num_samples=batch.shape[0])\n",
    "\n",
    "    # Evaluate using the discriminator. Recall class 1 is real.\n",
    "    fake_logits = self.disc_transform.apply(disc_params, fake_batch)\n",
    "    fake_probs = jax.nn.softmax(fake_logits)[:, 1]\n",
    "    loss = -jnp.log(fake_probs)\n",
    "\n",
    "    return jnp.mean(loss)\n",
    "\n",
    "  def disc_loss(self, disc_params, rng, gen_params, batch):\n",
    "    \"\"\"Discriminator loss.\"\"\"\n",
    "    # Sample from the generator.\n",
    "    fake_batch = self.sample(rng, gen_params, num_samples=batch.shape[0])\n",
    "\n",
    "    # For efficiency we process both the real and fake data in one pass.\n",
    "    real_and_fake_batch = jnp.concatenate([batch, fake_batch], axis=0)\n",
    "    real_and_fake_logits = self.disc_transform.apply(disc_params,\n",
    "                                                     real_and_fake_batch)\n",
    "    real_logits, fake_logits = jnp.split(real_and_fake_logits, 2, axis=0)\n",
    "\n",
    "    # Class 1 is real.\n",
    "    real_labels = jnp.ones((batch.shape[0],), dtype=jnp.int32)\n",
    "    real_loss = sparse_softmax_cross_entropy(real_logits, real_labels)\n",
    "\n",
    "    # Class 0 is fake.\n",
    "     fake_labels = jnp.zeros((batch.shape[0],), dtype=jnp.int32)\n",
    "    fake_loss = sparse_softmax_cross_entropy(fake_logits, fake_labels)\n",
    "\n",
    "    return jnp.mean(real_loss + fake_loss)\n",
    "\n",
    "  @functools.partial(jax.jit, static_argnums=0)\n",
    "  def update(self, rng, gan_state, batch):\n",
    "    \"\"\"Performs a parameter update.\"\"\"\n",
    "    rng, rng_gen, rng_disc = jax.random.split(rng, 3)\n",
    "\n",
    "    # Update the discriminator.\n",
    "    disc_loss, disc_grads = jax.value_and_grad(self.disc_loss)(\n",
    "        gan_state.params.disc,\n",
    "        rng_disc,\n",
    "        gan_state.params.gen,\n",
    "        batch)\n",
    "    disc_update, disc_opt_state = self.optimizers.disc.update(\n",
    "        disc_grads, gan_state.opt_state.disc)\n",
    "    disc_params = optax.apply_updates(gan_state.params.disc, disc_update)\n",
    "\n",
    "    # Update the generator.\n",
    "    gen_loss, gen_grads = jax.value_and_grad(self.gen_loss)(\n",
    "        gan_state.params.gen,\n",
    "        rng_gen,\n",
    "        gan_state.params.disc,\n",
    "        batch)\n",
    "    gen_update, gen_opt_state = self.optimizers.gen.update(\n",
    "        gen_grads, gan_state.opt_state.gen)\n",
    "    gen_params = optax.apply_updates(gan_state.params.gen, gen_update)\n",
    "    params = GANTuple(gen=gen_params, disc=disc_params)\n",
    "    opt_state = GANTuple(gen=gen_opt_state, disc=disc_opt_state)\n",
    "    gan_state = GANState(params=params, opt_state=opt_state)\n",
    "    log = {\n",
    "        \"gen_loss\": gen_loss,\n",
    "        \"disc_loss\": disc_loss,\n",
    "    }\n",
    "\n",
    "    return rng, gan_state, log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f104d",
   "metadata": {},
   "source": [
    "# Traning GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf27b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
